\section{Numeration systems}
Firstly, we give a general definition of numeration system.
\begin{defn}
  Let $\beta \in \CC, |\beta|>1$ and $\A \subset \CC$ be a finite set containing 0. A pair $(\beta, \A)$ is called a \emph{positional numeration system} with \emph{base} $\beta$ and \emph{digit set} $\A$, usually called \emph{alphabet}.
\end{defn}
So-called standard numeration systems have an integer base $\beta$ and an alphabet $\A$ which is a set of countiguous integers. We restrict ourselves to base $\beta$ which is an algebraic integer and possibly non-integer alphabet $\A$. 
\begin{defn}
Let $(\beta, \A)$ be a positional numeration system.  We say that a complex number $x$ has a \emph{$(\beta, \A)$-representation} if~ there exist digits $x_n,x_{n-1}, x_{n-2},\dots \in\A, n\geq 0$ such that $x=\sum_{j=-\infty}^n x_j \beta^j$.
\end{defn}
We associate a number $x$ with its  $(\beta, \A)$-representation as a bi-infinite string 
  $$
    (x)_{\beta,\A}=0^\omega x_n x_{n-1}\cdots x_1 x_0 \bullet x_{-1} x_{-2} \cdots\,,
  $$
  where $0^\omega$ denotes the infinite sequence of zeros. Notice that indices are decreasing from left to right as it is ussual to write the most significant digits first. We write briefly a \emph{representation} instead of a $(\beta, \A)$-representation, if the base $\beta$ and the alphabet $\A$ follow from context. 

\begin{defn}
Let $(\beta, \A)$ be a positional numeration system. The set of all complex numbers with a finite $(\beta, \A)$-representation is defined by
$$
    \fin{\A}:=\left\{\sum_{j=-m}^n x_j \beta^j\colon n, m \in \NN, x_j \in \A \right\}\,.
$$
\end{defn}
   
A representation of $x\in\fin{\A}$ is 
$$
(x)_{\beta,\A}= 0^\omega x_n x_{n-1}\cdots x_1 x_0 \bullet x_{-1} x_{-2} \cdots x_{-m} 0^\omega\,.
$$ 
In what follows, we omit the starting and ending $0^\omega$ when we work with numbers in $\fin{\A}$. We remark that existence of an algorithm (standard or parallel) producing a finite $(\beta,\A)$-representation of $x+y$ where $x,y\in\fin{\A}$ implies that the set $\fin{\A}$ is closed under addition, i.e.,
$$
\fin{\A} + \fin{\A} \subset \fin{\A}\,.
$$ 

Designing algorithm for parallel addition requires some redundancy in numeration system. 
\begin{defn}
A numeration system $(\beta,\A)$ is called \emph{redundant} if there exists $x \in \fin{\A}$ which has two different $(\beta,\A)$-representations.
\end{defn}
Redundant numeration system can enable us to avoid carry propagation in addition. On the other hand, thera are some disadvantages. For example, comparison is problematic.  


\section{Parallel addition}
A local function, which is also often called sliding block code, is used to mathematically formalize parallelism. 
\begin{defn}
Let $\A$ and $\B$ be alphabets. A function $\varphi:\B^\ZZ \rightarrow \A^\ZZ$ is said to be \emph{$p$-local} if there exist $r,t\in\NN$ satisfying $p=r+t+1$ and a function $\phi: \B^p \rightarrow \A$ such that, for any $w=(w_j)_{j\in\ZZ}\in\B^\ZZ$ and its image $z=\varphi(w)=(z_j)_{j\in\ZZ}\in\A^\ZZ$, we have $z_j=\phi(w_{j+t},\cdots,w_{j-r})$ for every $j\in\ZZ$. The parameter $t$, resp. $r$, is called \emph{anticipation}, resp. \emph{memory}.
\end{defn}
This means that each digit of the image $\varphi(w)$ is computed from $p$ digits of $w$ in a sliding window. Suppose that there is a processor on  each position with access to $t$ input digits on the left and $r$ input digits on the right. Then computation of $\varphi(w)$, where $w$ finite sequence, can be done in constant time independent on the length of $w$.   
  
\begin{defn}
\label{def:digitSetConversion}
Let $\beta$ be a base and $\A$ and $\B$ two alphabets containing 0. A function $\varphi:\B^\ZZ\rightarrow \A^\ZZ$ such that
  \begin{enumerate}
      \item for any $w=(w_j)_{j\in\ZZ}\in\B^\ZZ$ with finitely many non-zero digits, $z=\varphi(w)=(z_j)_{j\in\ZZ}\in\A^\ZZ$ has only finite number of non-zero digits, and
      \item $\sum_{j\in\ZZ} w_j \beta^j= \sum_{j\in\ZZ} z_j \beta^j$
  \end{enumerate}
  is called \emph{digit set conversion} in base $\beta$ from $\B$ to $\A$. Such a conversion $\varphi$ is said to be \emph{computable in parallel} if it is $p$-local function for some $p\in\NN$. 
\end{defn}
In fact, addition on $\fin{\A}$ can be performed in parallel if there is digit set conversion from $\A+\A$ to $\A$ computable in  parallel as we can easily output digitwise sum of two $(\beta,\A)$-representations in parallel.   

Now we recall known algorithms for parallel addition in different numeration systems. 
DODELAT 
    {Parallel Addition}
    Introduced by Avizienis in 1961:
  
  ROBERTSON
  For example:
  $$
  \beta \in \NN, \beta \geq 3, \A=\{-a, \dots, 0, \dots a\}, b/2 <a \leq b-1\,. 
  $$  
  MILENINY A EDITINY ALGORITMY -$>$ VETA S VELKOU INTEGEROVOU ABECEDOU
  
    Integer alphabets:
    \begin{itemize}
        \item Base $\beta \in \CC, |\beta|>1$.
        
        \item Addition is computable in parallel if and only if $\beta$ is an~algebraic number with no conjugate of modulus 1 [Frougny, Heller, Pelantov\'a, S. ].
        
        \item Algorithms are known but with large alphabets.
    \end{itemize}  
  LOWER BOUND VELIKOSTI ABECEDY
  
ZOBECNENI ABECEDY DO Z[OMEGA]   
\begin{defn}
Let $\omega$ be a complex number. The set of values of all polynomials with integer coefficients evaluated in $\omega$ is denoted by
$$
    \ZZ[\omega] =\left\{\sum_{i=0}^n a_i \omega^i\colon n\in\NN, a_i\in\ZZ \right\} \subset \QQ(\omega)\,.
$$
\end{defn}
For our purpose, the multiplicative group of a ring is associative   and with an indentity. Notice that $\ZZ[\omega]$ is a commutative ring.     
    
    Non-integer alphabets:
    \begin{itemize}
        \item Base $\beta \in \Zomega= \left\{\sum_{j=0}^{d-1} a_j \omega^j \colon a_j \in \ZZ \right\}$, where $\omega \in \CC$ is an~algebraic integer of degree $d$.
        
        \item Alphabet $\A \subset \Zomega , 0\in \A$.
        
        \item Only few manually found algorithms. 
        
        
    \end{itemize}
  


\section{\texorpdfstring{Isomorphism of $\Zomega$ and $\ZZ^{d}$}{Isomorphism of Z[omega] and Zd}}
The goal of this section is to show a connection between the ring $\Zomega$ and the set $\ZZ^d$. %It enables us to transform division in $\Zomega$ to search for an integer solution of a linear system. 

First we recall notion of companion matrix which we use to define multiplication in $\ZZ^d$.
\begin{defn}
Let $\omega$ be an algebraic integer of degree $d\geq 1$ with the monic minimal polynomial $p(x)=x^d +p_{d-1}x^{d-1}+ \cdots + p_1 x+p_0 \in \ZZ[x]$. A matrix 
$$
S := \begin{pmatrix}
            0 & 0 & \cdots & 0 & -p_0 \\
            1 & 0 & \cdots & 0 & -p_1 \\
            0 & 1 & \cdots & 0 & -p_2 \\
            \vdots &   & \ddots & & \vdots \\
            0 & 0 & \cdots & 1 & -p_{d-1} 
            \end{pmatrix} \in \ZZ^{d\times d}
$$
is called \emph{companion matrix} of the minimal polynomial of $\omega$.
\end{defn}
In what follows, the standard basis vectors of $\ZZ^d$  are denoted by 
$$
e_0=\begin{pmatrix}
              1 \\
              0 \\
              0 \\
              \vdots \\
              0
              \end{pmatrix}, \\
e_1=\begin{pmatrix}
              0 \\
              1 \\
              0 \\
              \vdots \\
              0
              \end{pmatrix}, \dots ,\\
e_{d-1}=\begin{pmatrix}
              0 \\        
              \vdots \\
              0 \\
              0\\
              1
              \end{pmatrix}\,.             
$$
% We remark that 1 in $e_i$ is in the $(i+1)$-st row because the index corresponds to the power of a companion matrix in the following definition. 

\begin{defn}
Let $\omega$ be an algebraic integer of degree $d\geq 1$, let $p$ be its minimal polynomial and let $S$ be its companion matrix. We define the mapping $\odot_\omega: \ZZ^d \times \ZZ^d \rightarrow \ZZ^d$ by 
$$
u \odot_\omega v := \left(\multMat{u}\right)\cdot \vect{v} \quad \text{ for all } u=\vect{u}, v=\vect{v} \in \ZZ^d\,.
$$ 
and we define powers of $u \in \ZZ^d$ by
\begin{align*}
    u^0&=e_0, \\
    u^{i}&= u^{i-1} \odot_\omega u \text{ for } i\in\NN\,.
\end{align*}
\end{defn}

We will see later that $\ZZ^d$ equipped with elementwise addition and multiplication $\odot_\omega$ builds a commutative ring. 
% It will follow from the isomorhpism with $\Zomega$. 
Let us first recall an important property of a companion matrix  -- it is a root of its defining polynomial.
\begin{lem}
\label{lem:compMatrixIsRoot}
Let $\omega$ be an algebraic integer with a minimal polynomial $p$ and let $S$ be its companion matrix. Then
$$
p(S)=0\,.
$$
\end{lem}
\begin{proof}
Following the proof in \cite{horn}, we have
\begin{align*}
e_0&=S^0 e_0\,, \\
S e_0= e_1&=S^1 e_0\,, \\
S e_1= e_2&=S^2 e_0\,, \\
S e_2= e_3&=S^3 e_0\,, \\
\vdots & \\
S e_{d-2}= e_{d-1}&=S^{d-1} e_0\,, \\
S e_{d-1} &= S^{d} e_0\,,
\end{align*}
where the middle column is obtained by multiplication and the right one by using the previous row. 
Also by multiplying and substituting
\begin{align*}
S^{d} e_0=S e_{d-1}&= -p_0e_0-p_1e_1-\cdots-p_{d-1}e_{d-1} \\
    &= -p_0 S^{0}e_0-p_1S^{1}e_0-\cdots-p_{d-1}S^{d-1}e_{0} \\
    &= (-p_0 S^{0}-p_1S^{1}-\cdots-p_{d-1}S^{d-1})e_{0} \\
    &=(S^{d}-p(S))e_0\,.
\end{align*}
Hence
$$
p(S)e_0=0\,.
$$
Moreover,
$$
p(S)e_k=p(S)S^k e_0=S^k p(S) e_0=0
$$
for $k=\{0,1,\dots,d-1\}$ which implies the statement.
\end{proof}

The following lemma summarises basic properties of the mapping $\odot_\omega$ -- multiplication by an integer scalar, the identity element, the distributive law and a weaker form of asociativity.
\begin{lem}
\label{lem:multInZd}
Let $\omega$ be an algebraic integer of degree $d$. The following statements hold for every $u,v,w\in \ZZ^d$ and $m\in\ZZ$:
\begin{enumerate}[(i)]
    \item $(mu)\odot_\omega v = u \odot_\omega (m v)= m (u\odot_\omega v)$,
    \item $e_0 \odot_\omega v= v \odot_\omega e_0 =v$,
    \item $(u \odot_\omega e_1^k)\odot_\omega v = u \odot_\omega (e_1^k\odot_\omega v)$ for $k\in\NN$,
    \item $(u+v)\odot_\omega w =u\odot_\omega w + v\odot_\omega w$ and $u \odot_\omega (v+w)= u \odot_\omega v +u\odot_\omega w$.
\end{enumerate}
\end{lem}
\begin{proof}
It is easy to see (i) as multiplication of a matrix by a scalar commutes and a scalar can be factored out of a sum. 

The first equality of (ii) follows from definition and
$$
v \odot_\omega e_0=\multMat{v}\cdot e_0= \sum_{i=0}^{d-1} v_i e_i = v\,.
$$
For (iii), we use Lemma \ref{lem:compMatrixIsRoot} and its proof. Assume $k=1$:
\begin{align*}
(u \odot_\omega e_1)\odot_\omega v &= \left(\multMat{u} \cdot e_1\right) \odot_\omega v = \left(\multMat{u} \cdot S e_0\right) \odot_\omega v \\
    &=\left(\sum_{i=0}^{d-2}u_i e_{i+1} + u_{d-1} S^d e_{0} \right)\odot_\omega v= \left(\sum_{i=1}^{d-1}u_{i-1} e_{i} - u_{d-1} \sum_{i=0}^{d-1} p_i e_{i} \right)\odot_\omega v \\
    &=\left(\sum_{i=1}^{d-1}u_{i-1}S^i - u_{d-1} \sum_{i=0}^{d-1}p_i S^i \right)\cdot v \\
    &=\left(\sum_{i=1}^{d-1}u_{i-1}S^i  + u_{d-1}S^d\right)\cdot v =\sum_{i=0}^{d-1}u_{i}S^i\cdot S\cdot v \\
    &=u \odot_\omega (S\cdot v)=u \odot_\omega (e_1\odot_\omega v)\,.
\end{align*}
Now we proceed by induction:
\begin{align*}
\left(u \odot_\omega e_1^k\right)\odot_\omega v &=\left(u \odot_\omega (e_1^{k-1}\odot_\omega e_1) \right)\odot_\omega v = \left((u \odot_\omega e_1^{k-1})\odot_\omega e_1 \right)\odot_\omega v \\
    &= (u \odot_\omega e_1^{k-1})\odot_\omega \left(e_1 \odot_\omega v \right)= u \odot_\omega \left( e_1^{k-1}\odot_\omega (e_1 \odot_\omega v )\right)\\
    &= u \odot_\omega \left(( e_1^{k-1}\odot_\omega e_1 )\odot_\omega v \right) = u \odot_\omega \left(e_1^k\odot_\omega v\right)\,.
\end{align*}
The statement (iv) follows easily from distributivity of matrix multiplication with respect to addition. 
\end{proof}




Now we can prove that there is a correspondence between elements of $\Zomega$ and $\ZZ^d$.

\begin{theo}
Let  $\omega$ be an algebraic integer of degree $d$. Then 
$$
\Zomega =\left\{\sum_{i=0}^{d-1} a_i \omega^i \colon a_i\in\ZZ \right\},
$$ 
$(\ZZ^d,+,\odot_\omega)$ is a commutative ring and the mapping $\pi:\Zomega \rightarrow \ZZ^{d}$ defined by 
$$
\pi(u)=\vect{u} \quad \text{ for every } u=\sum_{i=0}^{d-1} u_i \omega^i \in \Zomega
$$
is a ring isomorphism.
  
\end{theo}
\begin{proof}
Obviously, $\left\{\sum_{i=0}^{n} a_i \omega^i\colon n\in\NN, a_i\in\ZZ \right\}=\Zomega \supset \left\{\sum_{i=0}^{d-1} a_i \omega^i\colon a_i\in\ZZ \right\}$. We prove the opposite direction by the induction with respect to $n$. Assume $u\in \Zomega$, $u=\sum_{i=0}^n u_i \omega^i$ for some $n\in\NN$. We see that $u\in \left\{\sum_{i=0}^{d-1} a_i \omega^i\colon a_i\in\ZZ \right\}$ for all $n< d$. 

Suppose now that the claim holds for $n-1$ and consider $n\geq d$. Let $p(x)=x^d +p_{d-1}x^{d-1}+ \dots p_1 x+p_0$ be the minimal polynomial of $\omega$.  By $p(\omega)=0$, we have an equation $\omega^d =-p_{d-1}\omega^{d-1}- \dots -p_1\omega-p_0$ which enables us to write
\begin{align*}
u&=u_n\omega^n + \sum_{i=0}^{n-1} u_i \omega^i=u_n \omega^{n-d}(\underbrace{-p_{d-1}\omega^{d-1}- \dots -p_1\omega-p_0}_{\omega^d})+ \sum_{i=0}^{n-1} u_i \omega^i\\
    &=\sum_{i=0}^{n-d-1} u_i \omega^i+ \sum_{i=n-d}^{n-1} (u_i-u_n \cdot p_{i-n+d}) \omega^i=\sum_{i=0}^{n-1} u'_i \omega^i\,.
\end{align*}

Thus $u\in \left\{\sum_{i=0}^{d-1} a_i \omega^i \colon a_i\in\ZZ \right\}$ by the induction assumption.

Let us check now that the mapping $\pi$ is well-defined. Assume on contrary that there exists $v\in \Zomega$ and $i_0\in\{0,1,\dots,d-1\}$ such that $v=\sum_{i=0}^{d-1} v_i \omega^i=\sum_{i=0}^{d-1} v'_i \omega^i$ and $v_{i_0} \neq v'_{i_0}$. Then
$$
    \sum_{i=0}^{d-1} (v'_i-v_i) \omega^i=0
$$
and $\sum_{i=0}^{d-1} (v'_i-v_i) x^i \in \ZZ[x]$ is non-zero polynomial of degree smaller than the degree $d$ of minimal polynomial $p$, a contradiction.

Clearly, $\pi$ is bijection. Let $u=\sum_{i=0}^{d-1} u_i \omega^i$ and $v=\sum_{i=0}^{d-1} v_i \omega^i$ be elements of $\Zomega$. Consider
\begin{align*}
\omega v&=\omega \sum_{i=0}^{d-1} v_i \omega^i = \sum_{i=0}^{d-2} v_i \omega^{i+1} + v_{d-1}(\underbrace{-p_{d-1}\omega^{d-1}- \dots -p_1\omega-p_0}_{=\omega^d}) \\
&= -p_0 v_{d-1} + \sum_{i=1}^{d-1} (v_{i-1}- v_{d-1} p_i) \omega^i\,.
\end{align*}
Hence
\begin{align*}
\pi(\omega v)&= -p_0 v_{d-1} e_0 + \sum_{i=1}^{d-1} (v_{i-1}- v_{d-1} p_i) e_i = S \cdot \pi(v) \\
    &=e_1\odot_\omega \pi(v)=\pi(\omega)\odot_\omega\pi(v)\,.
\end{align*}
% \begin{align*}
% \pi(\omega v)&=\begin{pmatrix}
%               -v_{d-1}p_0 \\
%               v_0-v_{d-1}p_1 \\
%               v_1-v_{d-1}p_2 \\
%               \vdots \\
%               v_{d-2}-v_{d-1}p_{d-1}
%               \end{pmatrix}=\begin{pmatrix}
%             0 & 0 & \cdots & 0 & -p_0 \\
%             1 & 0 & \cdots & 0 & -p_1 \\
%             0 & 1 & \cdots & 0 & -p_2 \\
%             \vdots &   & \ddots & & \vdots \\
%             0 & 0 & \cdots & 1 & -p_{d-1} 
%             \end{pmatrix}\cdot\vect{v} \\
%             &=S \vect{v} =\begin{pmatrix}
%               0\\
%               1 \\
%               0 \\
%               \vdots \\
%               0
%               \end{pmatrix}\odot_\omega \vect{v}=\pi(\omega)\odot_\omega\pi(v)\,.
% \end{align*}
Suppose for induction with respect to $i$ that
$$
\pi(\omega^{i-1} v)=(\pi(\omega))^{i-1}\odot_\omega \pi(v)\,.
$$ 
Then
$$
\pi(\omega^{i}v)=\pi(\omega(\omega^{i-1} v))=\pi(\omega)\odot_\omega\pi(\omega^{i-1} v)=\pi(\omega)\odot_\omega\left((\pi(\omega))^{i-1}\odot_\omega \pi(v)\right)=(\pi(\omega))^{i}\odot_\omega \pi(v)\,,
$$
where we use (iii) of Lemma \ref{lem:multInZd} for the last equality.

Now we multiply $v$ by $m\in\ZZ\subset\Zomega$:
\begin{align*}
\pi(m v)&=\pi\left(m \sum_{i=0}^{d-1} v_i \omega^i\right)=\pi \left(\sum_{i=0}^{d-1} m v_i \omega^i\right)=m \pi(v)= (m e_0) \odot_\omega\pi(v)= \pi(m)\odot_\omega\pi(v)\,.
\end{align*}
% \begin{align*}
% \pi(m v)&=\pi(m \sum_{i=0}^{d-1} v_i \omega^i)=\pi(\sum_{i=0}^{d-1} m v_i \omega^i)=\vect{mv}=m \mathbb{I} \cdot \vect{v}=\begin{pmatrix}
%               m\\
%               0 \\
%               \vdots \\
%               0
%               \end{pmatrix}\odot_\omega \vect{v} \\
%         &= \pi(m)\odot_\omega\pi(v)\,.
% \end{align*}
As  $\pi$ is obviously additive, we conclude:
\begin{align*}
\pi(uv)&=\pi\left(\sum_{i=0}^{d-1} u_i \omega^i v\right)=\sum_{i=0}^{d-1}\pi(\omega^i u_i  v)=\sum_{i=0}^{d-1}\pi(\omega)^i \odot_\omega\left(\pi(u_i)\odot_\omega\pi(v)\right) \\
    &=\sum_{i=0}^{d-1}\pi(\omega^i u_i)\odot_\omega \pi(v)=\pi\left(\sum_{i=0}^{d-1}u_i\omega^i\right)\odot_\omega\pi(v)=\pi(u)\odot_\omega \pi(v)\,.
\end{align*}
\end{proof}
Due to this theorem we may work with integer vectors instead of elements of $\Zomega$ and multiplication in $\Zomega$ is replaced by multiplying by an appropriate matrix. We also obtained associativity and commutativity of $\odot_\omega$ as $\Zomega$ is an associative and commutative ring.

The last theorem of this section is a practical tool for divisibility in $\Zomega$. To check whether an element of $\Zomega$ is divisible by another element, we look for an integer solution of a linear system. Moreover, this solution provides a result of the division in the positive case. 
\begin{theo}
\label{thm:divisibility}
Let $\omega$ be an algebraic integer of degree $d$ and let $S$ be the companion matrix of its minimal polynomial. Let $\beta=\sum_{i=0}^{d-1} b_i \omega^i$ be a nonzero element of $\Zomega$. Then for every $u\in\Zomega$
$$
u\in\beta\Zomega \iff S_\beta^{-1}\cdot \pi(u) \in \ZZ^d\,,
$$
where $S_\beta=\multMat{b}$.
\end{theo}
\begin{proof}
Observe first that $S_\beta$ is nonsingular. Otherwise, there exists $y=\vect{y} \in \ZZ^d, y\neq \mathbf{0}$ such that $S_\beta \cdot y=0$. Thus
$$
\pi(\beta)\odot_\omega y=\mathbf{0} \iff \beta \pi^{-1}(y)=0\,.
$$
Since $\beta\neq 0$, we have
$$
0=\pi^{-1}(y)=\sum_{i=0}^{d-1} y_i \omega^i\,,
$$
which contradict that degree of $\omega$ is $d$.

Now
\begin{align*}
u\in\beta\Zomega &\iff (\exists v \in \Zomega)(u=\beta v)\\
    &\iff  (\exists v \in \Zomega)(\pi(u)=\pi(\beta)\odot_\omega\pi(v)=S_\beta \cdot \pi(v))\\
    &\iff \pi(v)=S_\beta^{-1} \cdot \pi(u) \in \ZZ^d\,.
\end{align*} 
Clearly, if $u$ is divisible by $\beta$, then $v=u/\beta= \pi^{-1}(S_\beta^{-1} \cdot \pi(u))\in\Zomega$.
\end{proof}























  
   